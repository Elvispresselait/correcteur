//
//  NSImage+ContentDetection.swift
//  Correcteur Pro
//
//  D√©tection intelligente du type de contenu d'une image
//

import AppKit
import CoreImage

// MARK: - Image Content Types

/// Type de contenu d√©tect√© dans l'image
enum ImageContentType {
    case text        // Capture d'√©cran avec texte (compression agressive)
    case photo       // Photo avec d√©tails (compression mod√©r√©e)
    case mixed       // Mixte texte + images (compression mod√©r√©e)
    case unknown     // Inconnu (compression conservatrice)

    var description: String {
        switch self {
        case .text: return "Text/Screenshot"
        case .photo: return "Photo"
        case .mixed: return "Mixed"
        case .unknown: return "Unknown"
        }
    }
}

// MARK: - Compression Profiles

/// Profil de compression adapt√© au type de contenu
struct CompressionProfile {
    let maxDimension: CGFloat
    let jpegQuality: CGFloat
    let maxSizeMB: Double
    let name: String

    var description: String {
        return "\(name): \(Int(maxDimension))px, Q\(String(format: "%.1f", jpegQuality)), \(String(format: "%.1f", maxSizeMB))MB"
    }
}

// MARK: - NSImage Extension

extension NSImage {

    // MARK: - Content Detection

    /// D√©tecte le type de contenu de l'image
    /// - Returns: Type de contenu d√©tect√©
    func detectContentType() -> ImageContentType {
        guard let cgImage = self.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
            print("‚ö†Ô∏è [Detection] Cannot convert to CGImage, assuming unknown")
            return .unknown
        }

        let width = cgImage.width
        let height = cgImage.height

        print("üîç [Detection] Analyzing image \(width)x\(height)...")

        // 1. V√©rifier les m√©tadonn√©es (si c'est une capture d'√©cran macOS)
        if isScreenshot() {
            print("‚úÖ [Detection] Detected as screenshot (metadata)")
            return .text
        }

        // 2. Analyser les propri√©t√©s de l'image
        let colorComplexity = analyzeColorComplexity(cgImage)
        let contrastRatio = analyzeContrast(cgImage)
        let uniformity = analyzeUniformity(cgImage)

        print("üìä [Detection] ColorComplexity: \(String(format: "%.2f", colorComplexity))")
        print("üìä [Detection] ContrastRatio: \(String(format: "%.2f", contrastRatio))")
        print("üìä [Detection] Uniformity: \(String(format: "%.2f", uniformity))")

        // 3. Heuristiques pour d√©tecter le type

        // Texte/Screenshot : peu de couleurs, contraste √©lev√©, zones uniformes
        if colorComplexity < 0.3 && contrastRatio > 0.6 && uniformity > 0.5 {
            print("‚úÖ [Detection] Detected as TEXT (low colors, high contrast)")
            return .text
        }

        // Photo : beaucoup de couleurs, faible uniformit√©
        if colorComplexity > 0.6 && uniformity < 0.3 {
            print("‚úÖ [Detection] Detected as PHOTO (many colors, low uniformity)")
            return .photo
        }

        // Mixte : entre les deux
        if colorComplexity > 0.3 && colorComplexity < 0.6 {
            print("‚úÖ [Detection] Detected as MIXED (medium complexity)")
            return .mixed
        }

        print("‚ö†Ô∏è [Detection] Detected as UNKNOWN (fallback)")
        return .unknown
    }

    // MARK: - Analysis Methods

    /// V√©rifie si l'image est une capture d'√©cran macOS
    private func isScreenshot() -> Bool {
        // V√©rifier les propri√©t√©s TIFF pour d√©tecter une capture d'√©cran
        guard let tiffData = self.tiffRepresentation,
              let imageSource = CGImageSourceCreateWithData(tiffData as CFData, nil),
              let properties = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, nil) as? [String: Any] else {
            return false
        }

        // Chercher des indices de capture d'√©cran
        // (Note: Cette m√©thode est basique, Vision Framework serait plus pr√©cis)
        if let dpiWidth = properties[kCGImagePropertyDPIWidth as String] as? Double,
           let dpiHeight = properties[kCGImagePropertyDPIHeight as String] as? Double {
            // Les captures d'√©cran macOS ont souvent 144 DPI (Retina) ou 72 DPI
            return (dpiWidth == 144.0 && dpiHeight == 144.0) || (dpiWidth == 72.0 && dpiHeight == 72.0)
        }

        return false
    }

    /// Analyse la complexit√© des couleurs (0.0 = peu de couleurs, 1.0 = beaucoup)
    private func analyzeColorComplexity(_ cgImage: CGImage) -> Double {
        // √âchantillonner l'image pour compter les couleurs uniques
        let sampleSize = 100 // √âchantillonner tous les 100 pixels pour performance

        guard let dataProvider = cgImage.dataProvider,
              let data = dataProvider.data,
              let pixelData = CFDataGetBytePtr(data) else {
            return 0.5 // Valeur par d√©faut si √©chec
        }

        let bytesPerPixel = cgImage.bitsPerPixel / 8
        let bytesPerRow = cgImage.bytesPerRow
        let width = cgImage.width
        let height = cgImage.height

        var colorSet = Set<Int>()
        var sampleCount = 0

        for y in stride(from: 0, to: height, by: sampleSize) {
            for x in stride(from: 0, to: width, by: sampleSize) {
                let pixelIndex = y * bytesPerRow + x * bytesPerPixel

                if pixelIndex + 2 < CFDataGetLength(data) {
                    let r = pixelData[pixelIndex]
                    let g = pixelData[pixelIndex + 1]
                    let b = pixelData[pixelIndex + 2]

                    // Quantifier la couleur pour r√©duire bruit
                    let quantized = (Int(r / 32) << 10) | (Int(g / 32) << 5) | Int(b / 32)
                    colorSet.insert(quantized)
                    sampleCount += 1
                }
            }
        }

        let uniqueColors = Double(colorSet.count)
        let maxExpectedColors = Double(sampleCount) * 0.5 // 50% des √©chantillons max

        return min(1.0, uniqueColors / maxExpectedColors)
    }

    /// Analyse le ratio de contraste (0.0 = faible, 1.0 = √©lev√©)
    private func analyzeContrast(_ cgImage: CGImage) -> Double {
        guard let dataProvider = cgImage.dataProvider,
              let data = dataProvider.data,
              let pixelData = CFDataGetBytePtr(data) else {
            return 0.5
        }

        let bytesPerPixel = cgImage.bitsPerPixel / 8
        let bytesPerRow = cgImage.bytesPerRow
        let width = cgImage.width
        let height = cgImage.height
        let sampleSize = 100

        var minBrightness: Double = 255.0
        var maxBrightness: Double = 0.0

        for y in stride(from: 0, to: height, by: sampleSize) {
            for x in stride(from: 0, to: width, by: sampleSize) {
                let pixelIndex = y * bytesPerRow + x * bytesPerPixel

                if pixelIndex + 2 < CFDataGetLength(data) {
                    let r = Double(pixelData[pixelIndex])
                    let g = Double(pixelData[pixelIndex + 1])
                    let b = Double(pixelData[pixelIndex + 2])

                    // Luminosit√© per√ßue
                    let brightness = 0.299 * r + 0.587 * g + 0.114 * b

                    minBrightness = min(minBrightness, brightness)
                    maxBrightness = max(maxBrightness, brightness)
                }
            }
        }

        let contrastRatio = (maxBrightness - minBrightness) / 255.0
        return contrastRatio
    }

    /// Analyse l'uniformit√© (0.0 = vari√©, 1.0 = uniforme)
    private func analyzeUniformity(_ cgImage: CGImage) -> Double {
        guard let dataProvider = cgImage.dataProvider,
              let data = dataProvider.data,
              let pixelData = CFDataGetBytePtr(data) else {
            return 0.5
        }

        let bytesPerPixel = cgImage.bitsPerPixel / 8
        let bytesPerRow = cgImage.bytesPerRow
        let width = cgImage.width
        let height = cgImage.height
        let sampleSize = 100

        var lightPixels = 0
        var darkPixels = 0
        var totalSamples = 0

        for y in stride(from: 0, to: height, by: sampleSize) {
            for x in stride(from: 0, to: width, by: sampleSize) {
                let pixelIndex = y * bytesPerRow + x * bytesPerPixel

                if pixelIndex + 2 < CFDataGetLength(data) {
                    let r = Double(pixelData[pixelIndex])
                    let g = Double(pixelData[pixelIndex + 1])
                    let b = Double(pixelData[pixelIndex + 2])

                    let brightness = 0.299 * r + 0.587 * g + 0.114 * b

                    if brightness > 200 {
                        lightPixels += 1
                    } else if brightness < 55 {
                        darkPixels += 1
                    }

                    totalSamples += 1
                }
            }
        }

        // Plus il y a de pixels tr√®s clairs ou tr√®s fonc√©s, plus c'est uniforme (typique du texte)
        let uniformPixels = Double(lightPixels + darkPixels)
        let uniformity = uniformPixels / Double(totalSamples)

        return uniformity
    }

    // MARK: - Compression Profiles

    /// Retourne le profil de compression optimal selon le type de contenu et la qualit√©
    /// - Parameters:
    ///   - contentType: Type de contenu d√©tect√©
    ///   - quality: Niveau de qualit√© souhait√©
    /// - Returns: Profil de compression adapt√©
    static func compressionProfile(for contentType: ImageContentType,
                                  quality: CompressionQuality) -> CompressionProfile {
        switch (contentType, quality) {
        // TEXT - Compression agressive
        case (.text, .high):
            return CompressionProfile(maxDimension: 1024, jpegQuality: 0.4, maxSizeMB: 0.5, name: "Text-High")
        case (.text, .medium):
            return CompressionProfile(maxDimension: 1280, jpegQuality: 0.5, maxSizeMB: 0.8, name: "Text-Medium")
        case (.text, .low):
            return CompressionProfile(maxDimension: 1600, jpegQuality: 0.6, maxSizeMB: 1.5, name: "Text-Low")
        case (.text, .none):
            return CompressionProfile(maxDimension: 2048, jpegQuality: 0.7, maxSizeMB: 5.0, name: "Text-None")

        // PHOTO - Compression mod√©r√©e
        case (.photo, .high):
            return CompressionProfile(maxDimension: 1600, jpegQuality: 0.6, maxSizeMB: 1.5, name: "Photo-High")
        case (.photo, .medium):
            return CompressionProfile(maxDimension: 1920, jpegQuality: 0.7, maxSizeMB: 2.5, name: "Photo-Medium")
        case (.photo, .low):
            return CompressionProfile(maxDimension: 2048, jpegQuality: 0.8, maxSizeMB: 4.0, name: "Photo-Low")
        case (.photo, .none):
            return CompressionProfile(maxDimension: 3840, jpegQuality: 0.9, maxSizeMB: 10.0, name: "Photo-None")

        // MIXED - Entre les deux
        case (.mixed, .high):
            return CompressionProfile(maxDimension: 1280, jpegQuality: 0.5, maxSizeMB: 1.0, name: "Mixed-High")
        case (.mixed, .medium):
            return CompressionProfile(maxDimension: 1600, jpegQuality: 0.6, maxSizeMB: 1.8, name: "Mixed-Medium")
        case (.mixed, .low):
            return CompressionProfile(maxDimension: 1920, jpegQuality: 0.7, maxSizeMB: 3.0, name: "Mixed-Low")
        case (.mixed, .none):
            return CompressionProfile(maxDimension: 2560, jpegQuality: 0.8, maxSizeMB: 8.0, name: "Mixed-None")

        // UNKNOWN - Conservatif
        case (.unknown, .high):
            return CompressionProfile(maxDimension: 1600, jpegQuality: 0.6, maxSizeMB: 1.5, name: "Unknown-High")
        case (.unknown, .medium):
            return CompressionProfile(maxDimension: 1920, jpegQuality: 0.7, maxSizeMB: 2.5, name: "Unknown-Medium")
        case (.unknown, .low):
            return CompressionProfile(maxDimension: 2048, jpegQuality: 0.8, maxSizeMB: 4.0, name: "Unknown-Low")
        case (.unknown, .none):
            return CompressionProfile(maxDimension: 3840, jpegQuality: 0.9, maxSizeMB: 10.0, name: "Unknown-None")
        }
    }
}
