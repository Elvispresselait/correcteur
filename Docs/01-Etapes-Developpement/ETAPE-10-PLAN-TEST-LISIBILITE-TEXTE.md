# √âTAPE 10 : Plan de test de lisibilit√© du texte dans les images

**Date** : 29 novembre 2024
**Objectif** : Impl√©menter un syst√®me de test interne pour valider automatiquement la lisibilit√© du texte apr√®s compression

---

## üìã Vue d'ensemble

### Probl√©matique

Lors de l'optimisation de la compression (√âTAPE 9), nous devons **v√©rifier automatiquement** que le texte reste lisible apr√®s compression. Actuellement, cette validation se fait manuellement.

### Solution propos√©e

Utiliser **Vision Framework** d'Apple (OCR int√©gr√© macOS) pour :
1. Extraire le texte de l'image **avant** compression
2. Extraire le texte de l'image **apr√®s** compression
3. **Comparer** les deux r√©sultats
4. **Valider** que la lisibilit√© est maintenue

---

## üéØ Objectifs

### Objectif principal

Cr√©er un syst√®me de validation automatique de la qualit√© de compression bas√© sur la reconnaissance de texte.

### Objectifs mesurables

| M√©trique | Description | Seuil de validation |
|----------|-------------|---------------------|
| **Taux de reconnaissance** | % de texte reconnu apr√®s compression | ‚â• 95% |
| **Pr√©cision des caract√®res** | % de caract√®res identiques | ‚â• 98% |
| **Confiance OCR** | Score de confiance Vision Framework | ‚â• 0.7 |
| **Performance** | Temps de validation | < 2 secondes |

### Cas d'usage

1. **D√©veloppement** : Valider les nouveaux profils de compression
2. **Tests automatis√©s** : CI/CD pour v√©rifier la qualit√©
3. **Debugging** : Identifier pourquoi une compression √©choue
4. **Monitoring** : Logs de qualit√© pour am√©lioration continue

---

## üîß Architecture technique

### Vision Framework (macOS 10.15+)

Apple fournit un OCR natif ultra-performant :

```swift
import Vision
import CoreImage

class TextRecognitionService {
    /// Extrait le texte d'une image
    static func extractText(from image: NSImage) async throws -> RecognizedText {
        // 1. Convertir NSImage ‚Üí CGImage
        // 2. Cr√©er VNRecognizeTextRequest
        // 3. Ex√©cuter la reconnaissance
        // 4. Retourner le texte + confiance
    }

    /// Compare deux r√©sultats OCR
    static func compareTexts(_ original: RecognizedText,
                            _ compressed: RecognizedText) -> QualityScore {
        // Calculer similarit√©, confiance, etc.
    }
}

struct RecognizedText {
    let fullText: String
    let lines: [TextLine]
    let confidence: Float
    let characterCount: Int
}

struct TextLine {
    let text: String
    let confidence: Float
    let boundingBox: CGRect
}

struct QualityScore {
    let recognitionRate: Float      // 0.0 - 1.0
    let characterAccuracy: Float    // 0.0 - 1.0
    let averageConfidence: Float    // 0.0 - 1.0
    let isPassing: Bool             // true si tous les seuils OK
    let details: String             // Explication
}
```

---

## üìä Workflow complet

### Sc√©nario 1 : Validation compression (d√©veloppement)

```
1. User d√©clenche compression d'une capture d'√©cran
   ‚Üì
2. CompressionService :
   a. Garde r√©f√©rence √† l'image originale
   b. Applique la compression optimis√©e
   c. Obtient l'image compress√©e
   ‚Üì
3. TextRecognitionService :
   a. Extrait texte de l'originale
   b. Extrait texte de la compress√©e
   c. Compare les r√©sultats
   ‚Üì
4. Validation :
   ‚úÖ Si QualityScore.isPassing = true ‚Üí Utiliser image compress√©e
   ‚ùå Si QualityScore.isPassing = false ‚Üí Fallback compression moins agressive
   ‚Üì
5. Logging :
   - Log le QualityScore pour analyse
   - Permet d'ajuster les profils de compression
```

### Sc√©nario 2 : Tests automatis√©s

```swift
func testCompressionQuality() async throws {
    // 1. Charger image de test
    let testImage = loadTestImage("code_screenshot.png")

    // 2. Appliquer compression
    let compressed = testImage.compressOptimized(quality: .high)

    // 3. Valider qualit√©
    let quality = try await TextQualityValidator.validate(
        original: testImage,
        compressed: compressed
    )

    // 4. Assert
    XCTAssertTrue(quality.isPassing)
    XCTAssertGreaterThan(quality.recognitionRate, 0.95)
}
```

---

## üõ†Ô∏è Impl√©mentation

### Phase 1 : Service de reconnaissance texte (3-4h)

**Fichier** : `Correcteur Pro/Utilities/TextRecognitionService.swift`

```swift
import Vision
import CoreImage
import AppKit

/// Service pour extraire et comparer du texte dans les images
class TextRecognitionService {

    // MARK: - Types

    struct RecognizedText {
        let fullText: String
        let lines: [TextLine]
        let confidence: Float
        let characterCount: Int

        var isEmpty: Bool {
            return fullText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty
        }
    }

    struct TextLine {
        let text: String
        let confidence: Float
        let boundingBox: CGRect
    }

    struct QualityScore {
        let recognitionRate: Float      // % texte reconnu
        let characterAccuracy: Float    // % caract√®res identiques
        let averageConfidence: Float    // Confiance moyenne OCR
        let originalCount: Int
        let compressedCount: Int
        let isPassing: Bool
        let details: String

        static func failing(reason: String) -> QualityScore {
            return QualityScore(
                recognitionRate: 0.0,
                characterAccuracy: 0.0,
                averageConfidence: 0.0,
                originalCount: 0,
                compressedCount: 0,
                isPassing: false,
                details: reason
            )
        }
    }

    // MARK: - OCR Methods

    /// Extrait le texte d'une image en utilisant Vision Framework
    static func extractText(from image: NSImage) async throws -> RecognizedText {
        guard let cgImage = image.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
            throw NSError(domain: "TextRecognition", code: 1, userInfo: [
                NSLocalizedDescriptionKey: "Cannot convert NSImage to CGImage"
            ])
        }

        return try await withCheckedThrowingContinuation { continuation in
            // Cr√©er la requ√™te de reconnaissance
            let request = VNRecognizeTextRequest { request, error in
                if let error = error {
                    continuation.resume(throwing: error)
                    return
                }

                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    continuation.resume(returning: RecognizedText(
                        fullText: "",
                        lines: [],
                        confidence: 0.0,
                        characterCount: 0
                    ))
                    return
                }

                // Extraire le texte de chaque observation
                var lines: [TextLine] = []
                var fullText = ""
                var totalConfidence: Float = 0.0

                for observation in observations {
                    guard let topCandidate = observation.topCandidates(1).first else { continue }

                    let line = TextLine(
                        text: topCandidate.string,
                        confidence: topCandidate.confidence,
                        boundingBox: observation.boundingBox
                    )

                    lines.append(line)
                    fullText += topCandidate.string + "\n"
                    totalConfidence += topCandidate.confidence
                }

                let averageConfidence = lines.isEmpty ? 0.0 : totalConfidence / Float(lines.count)

                let result = RecognizedText(
                    fullText: fullText,
                    lines: lines,
                    confidence: averageConfidence,
                    characterCount: fullText.count
                )

                continuation.resume(returning: result)
            }

            // Configurer pour meilleure reconnaissance
            request.recognitionLevel = .accurate
            request.usesLanguageCorrection = true
            request.recognitionLanguages = ["fr-FR", "en-US"]

            // Ex√©cuter la requ√™te
            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            do {
                try handler.perform([request])
            } catch {
                continuation.resume(throwing: error)
            }
        }
    }

    // MARK: - Comparison Methods

    /// Compare deux r√©sultats OCR et calcule un score de qualit√©
    static func compareTexts(_ original: RecognizedText,
                            _ compressed: RecognizedText) -> QualityScore {
        // Si l'original est vide, pas de texte √† valider
        if original.isEmpty {
            return QualityScore(
                recognitionRate: 1.0,
                characterAccuracy: 1.0,
                averageConfidence: compressed.confidence,
                originalCount: 0,
                compressedCount: 0,
                isPassing: true,
                details: "No text to validate (original is empty)"
            )
        }

        // Si la compression a perdu tout le texte
        if compressed.isEmpty {
            return .failing(reason: "Compressed image has no recognizable text")
        }

        // 1. Calculer le taux de reconnaissance (nombre de caract√®res)
        let originalCount = original.characterCount
        let compressedCount = compressed.characterCount
        let recognitionRate = Float(compressedCount) / Float(originalCount)

        // 2. Calculer la pr√©cision des caract√®res (similarit√© Levenshtein)
        let characterAccuracy = calculateSimilarity(
            original.fullText,
            compressed.fullText
        )

        // 3. Confiance moyenne
        let averageConfidence = compressed.confidence

        // 4. Validation des seuils
        let passingRecognitionRate = recognitionRate >= 0.95
        let passingCharacterAccuracy = characterAccuracy >= 0.98
        let passingConfidence = averageConfidence >= 0.7

        let isPassing = passingRecognitionRate && passingCharacterAccuracy && passingConfidence

        // 5. D√©tails
        var details = "Recognition: \(String(format: "%.1f%%", recognitionRate * 100))"
        details += ", Accuracy: \(String(format: "%.1f%%", characterAccuracy * 100))"
        details += ", Confidence: \(String(format: "%.1f%%", averageConfidence * 100))"

        if !isPassing {
            details += " | "
            if !passingRecognitionRate {
                details += "‚ö†Ô∏è Low recognition rate. "
            }
            if !passingCharacterAccuracy {
                details += "‚ö†Ô∏è Low character accuracy. "
            }
            if !passingConfidence {
                details += "‚ö†Ô∏è Low OCR confidence. "
            }
        }

        return QualityScore(
            recognitionRate: recognitionRate,
            characterAccuracy: characterAccuracy,
            averageConfidence: averageConfidence,
            originalCount: originalCount,
            compressedCount: compressedCount,
            isPassing: isPassing,
            details: details
        )
    }

    /// Calcule la similarit√© entre deux textes (distance de Levenshtein normalis√©e)
    private static func calculateSimilarity(_ text1: String, _ text2: String) -> Float {
        let distance = levenshteinDistance(text1, text2)
        let maxLength = max(text1.count, text2.count)

        guard maxLength > 0 else { return 1.0 }

        let similarity = 1.0 - (Float(distance) / Float(maxLength))
        return max(0.0, similarity)
    }

    /// Distance de Levenshtein (nombre de modifications n√©cessaires)
    private static func levenshteinDistance(_ s1: String, _ s2: String) -> Int {
        let len1 = s1.count
        let len2 = s2.count

        var matrix = [[Int]](repeating: [Int](repeating: 0, count: len2 + 1), count: len1 + 1)

        for i in 0...len1 { matrix[i][0] = i }
        for j in 0...len2 { matrix[0][j] = j }

        let s1Array = Array(s1)
        let s2Array = Array(s2)

        for i in 1...len1 {
            for j in 1...len2 {
                let cost = s1Array[i - 1] == s2Array[j - 1] ? 0 : 1
                matrix[i][j] = min(
                    matrix[i - 1][j] + 1,      // deletion
                    matrix[i][j - 1] + 1,      // insertion
                    matrix[i - 1][j - 1] + cost // substitution
                )
            }
        }

        return matrix[len1][len2]
    }
}
```

---

### Phase 2 : Int√©gration dans compression (2-3h)

**Fichier** : `Correcteur Pro/Utilities/TextQualityValidator.swift`

```swift
import AppKit

/// Validateur de qualit√© pour compression d'images avec texte
class TextQualityValidator {

    /// Valide la qualit√© d'une compression en comparant l'OCR
    static func validate(original: NSImage, compressed: NSImage?) async throws -> TextRecognitionService.QualityScore {
        guard let compressed = compressed else {
            return .failing(reason: "Compressed image is nil")
        }

        print("üìù [Quality] Extracting text from original image...")
        let originalText = try await TextRecognitionService.extractText(from: original)
        print("‚úÖ [Quality] Original: \(originalText.characterCount) chars, confidence: \(String(format: "%.2f", originalText.confidence))")

        print("üìù [Quality] Extracting text from compressed image...")
        let compressedText = try await TextRecognitionService.extractText(from: compressed)
        print("‚úÖ [Quality] Compressed: \(compressedText.characterCount) chars, confidence: \(String(format: "%.2f", compressedText.confidence))")

        let score = TextRecognitionService.compareTexts(originalText, compressedText)

        if score.isPassing {
            print("‚úÖ [Quality] PASSED: \(score.details)")
        } else {
            print("‚ùå [Quality] FAILED: \(score.details)")
        }

        return score
    }

    /// Compresse avec validation automatique et fallback
    static func compressWithValidation(
        image: NSImage,
        quality: CompressionQuality,
        maxAttempts: Int = 3
    ) async throws -> NSImage {
        var currentQuality = quality

        for attempt in 1...maxAttempts {
            print("üîß [Quality] Compression attempt \(attempt)/\(maxAttempts) with quality: \(currentQuality)")

            // Appliquer compression
            guard let compressed = image.compressOptimized(userQuality: currentQuality) else {
                throw NSError(domain: "Compression", code: 1, userInfo: [
                    NSLocalizedDescriptionKey: "Compression failed"
                ])
            }

            // Valider qualit√©
            let score = try await validate(original: image, compressed: compressed)

            if score.isPassing {
                print("‚úÖ [Quality] Compression successful!")
                return compressed
            }

            // Si √©chec et pas dernier essai, r√©duire la compression
            if attempt < maxAttempts {
                currentQuality = currentQuality.lesserCompression()
                print("‚ö†Ô∏è [Quality] Quality check failed, retrying with less compression...")
            }
        }

        print("‚ùå [Quality] All attempts failed, using original")
        return image
    }
}

// Extension pour r√©duire niveau de compression
extension CompressionQuality {
    func lesserCompression() -> CompressionQuality {
        switch self {
        case .high: return .medium
        case .medium: return .low
        case .low: return .none
        case .none: return .none
        }
    }
}
```

---

### Phase 3 : Tests automatis√©s (2-3h)

**Fichier** : `Correcteur Pro Tests/TextRecognitionTests.swift`

```swift
import XCTest
@testable import Correcteur_Pro

class TextRecognitionTests: XCTestCase {

    func testExtractTextFromCodeScreenshot() async throws {
        // Charger image de test
        let testImage = loadTestImage("code_screenshot")

        // Extraire texte
        let result = try await TextRecognitionService.extractText(from: testImage)

        // V√©rifications
        XCTAssertFalse(result.isEmpty)
        XCTAssertGreaterThan(result.characterCount, 100)
        XCTAssertGreaterThan(result.confidence, 0.7)
    }

    func testCompressionQualityHigh() async throws {
        let original = loadTestImage("document_text")
        let compressed = original.compressOptimized(quality: .high)

        let score = try await TextQualityValidator.validate(
            original: original,
            compressed: compressed
        )

        XCTAssertTrue(score.isPassing)
        XCTAssertGreaterThan(score.recognitionRate, 0.95)
        XCTAssertGreaterThan(score.characterAccuracy, 0.98)
    }

    func testCompressionWithValidation() async throws {
        let testImage = loadTestImage("mixed_content")

        let result = try await TextQualityValidator.compressWithValidation(
            image: testImage,
            quality: .high
        )

        XCTAssertNotNil(result)
    }
}
```

---

### Phase 4 : Interface de debug (optionnel, 1-2h)

Ajouter dans le panneau Pr√©f√©rences un onglet "Debug" :

```swift
struct DebugPreferencesView: View {
    @State private var testResult: String = ""
    @State private var isLoading = false

    var body: some View {
        VStack(alignment: .leading, spacing: 16) {
            Text("Test de qualit√© OCR")
                .font(.headline)

            Button("Tester derni√®re capture") {
                testLastCapture()
            }

            if isLoading {
                ProgressView()
            }

            Text(testResult)
                .font(.system(.body, design: .monospaced))
        }
        .padding()
    }

    func testLastCapture() {
        // Impl√©menter test
    }
}
```

---

## üìä Planning

### Estimation totale : 7-12 heures

| Phase | Description | Dur√©e | Priorit√© |
|-------|-------------|-------|----------|
| 1 | TextRecognitionService | 3-4h | üî¥ Haute |
| 2 | TextQualityValidator | 2-3h | üî¥ Haute |
| 3 | Tests automatis√©s | 2-3h | üü° Moyenne |
| 4 | Interface debug | 1-2h | üü¢ Basse |

---

## üéØ R√©sultats attendus

### Avant (sans validation)

- ‚ùå Compression manuelle
- ‚ùå Validation visuelle uniquement
- ‚ùå Risque de perte de lisibilit√©
- ‚ùå Pas de mesure objective

### Apr√®s (avec validation)

- ‚úÖ Compression automatique valid√©e
- ‚úÖ Score objectif de qualit√©
- ‚úÖ Fallback automatique si √©chec
- ‚úÖ Logs pour optimisation continue
- ‚úÖ Tests automatis√©s

---

## üîó Int√©gration avec √âTAPE 9

Cette √©tape compl√®te l'√âTAPE 9 (Optimisation compression) :

```
√âTAPE 9: Optimisation compression
    ‚Üì
    Cr√©e profils agressifs
    ‚Üì
√âTAPE 10: Test lisibilit√© ‚Üê (CE PLAN)
    ‚Üì
    Valide que texte reste lisible
    ‚Üì
    Ajuste automatiquement si besoin
```

---

## üìù Notes importantes

1. **Vision Framework requis** : macOS 10.15+ (d√©j√† support√©)
2. **Performance** : OCR prend ~0.5-1s par image
3. **Langues** : Configure fr-FR et en-US par d√©faut
4. **Pr√©cision** : Vision Framework tr√®s performant (~95%+ sur texte clair)

---

## üöÄ Prochaines √©tapes

Apr√®s impl√©mentation :

1. **Collecter donn√©es** : Logger scores sur 100+ compressions
2. **Ajuster seuils** : Affiner les 95%/98%/70% selon r√©sultats r√©els
3. **Optimiser profils** : Utiliser les scores pour am√©liorer √âTAPE 9
4. **Machine Learning** (futur) : Pr√©dire meilleur profil selon image

---

**Statut** : ‚è≥ EN ATTENTE DE VALIDATION
**D√©pend de** : √âTAPE 9 (Optimisation compression)
**Cr√©√© le** : 29 novembre 2024
